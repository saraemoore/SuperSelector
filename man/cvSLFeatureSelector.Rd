% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/select.R
\name{cvSLFeatureSelector}
\alias{cvSLFeatureSelector}
\title{Feature selection via \code{CV.SuperLearner}}
\usage{
cvSLFeatureSelector(
  Y,
  X,
  family = binomial(),
  obsWeights = NULL,
  id = NULL,
  method = "method.NNloglik",
  SL.library = list(c("SL.mean", "screen.corP"), c("SL.mean", "screen.glmnet"),
    c("SL.mean", "screen.randomForest")),
  selector.library = data.frame(selector = "cutoff.biggest.diff", k = NA,
    stringsAsFactors = FALSE),
  nFolds = c(outer = 10, inner = 10),
  trimLogit = 0.001,
  stratifyCV = (family$family == "binomial"),
  shuffle = TRUE,
  validRows = NULL,
  weighted = FALSE,
  verbose = FALSE,
  label = NULL,
  ...
)
}
\arguments{
\item{Y}{Outcome (numeric vector). See \code{\link[SuperLearner]{CV.SuperLearner}}.}

\item{X}{Predictor variable(s) (data.frame or matrix). See
\code{\link[SuperLearner]{CV.SuperLearner}}.}

\item{family}{Error distribution to be used in the model:
\code{\link[stats]{gaussian}} or \code{\link[stats]{binomial}}.
See \code{\link[SuperLearner]{CV.SuperLearner}}.}

\item{obsWeights}{Optional numeric vector of observation weights. See
\code{\link[SuperLearner]{CV.SuperLearner}}.}

\item{id}{Cluster identification variable. See
\code{\link[SuperLearner]{CV.SuperLearner}}.}

\item{method}{A list of method(s) by which \code{\link[SuperLearner]{CV.SuperLearner}} should
estimate coefficients to combine algorithms.}

\item{SL.library}{A list of character vectors of length 2, each containing a screener algorithm
and a prediction algorithm. See \code{\link[SuperLearner]{SuperLearner}}.}

\item{selector.library}{A \code{data.frame} with 2 columns: "selector" and "k". The "selector" column should contain strings naming selector functions (typically from the \code{\link[FSelector]{FSelector}} package, with a prefix of \code{cutoff.}). The "k" column should be the required second argument to the named "selector" function (usually named \code{k}), if one exists. If there is no second argument, column "k" should be set to \code{NA}. Rownames will be utilized if they are included.}

\item{nFolds}{numeric of length 1 or 2. If length(nFolds)==1, the value provided will be used as the number of cross-validation folds for both the outer (\code{\link[SuperLearner]{CV.SuperLearner}}) and inner (SuperLearner) cross-validations. If length(nFolds)==2, the first element or element with name "outer" will be used as the number of folds for the outer (\code{\link[SuperLearner]{CV.SuperLearner}}) cross-validation, and the second element or element with name "inner" will be used as the number of folds for the inner (SuperLearner) cross-validation.}

\item{trimLogit}{Only applicable when using the \code{NNloglik} method. See
\code{\link[SuperLearner]{SuperLearner.control}}.}

\item{stratifyCV}{Only applicable when \code{Y} is binary. If \code{TRUE},
\code{\link[SuperLearner]{CV.SuperLearner}} will stratify CV splits by \code{Y}. See
\code{\link[SuperLearner]{SuperLearner.CV.control}}.}

\item{shuffle}{If \code{TRUE}, rows of \code{X} will be shuffled before being split. See
\code{\link[SuperLearner]{SuperLearner.CV.control}}.}

\item{validRows}{A list containing pre-specified rows for the CV splits. See
\code{\link[SuperLearner]{SuperLearner.CV.control}}.}

\item{weighted}{Should the weights estimated by the method(s) be used to weight the feature
selection? Passed to \link{extractScreen.CV.SuperLearner}.}

\item{verbose}{Print diagnostic messages? Defaults to FALSE}

\item{label}{An optional named character vector of length 1. If specified, the value will be added as a column (where the column name is set to \code{names(label)}) in the \code{data.frame} stored in the \code{summary} element of the \code{cvslFull} element of the returned list. One example of when this might be useful is when this function is called from within a cross-validation fold. Then, \code{label} might be set to, for example, \code{c(metafold = fold$v)}.}

\item{...}{Passed through to \code{\link[SuperLearner]{CV.SuperLearner}}}
}
\value{
A named list containing the results of the \code{\link[SuperLearner]{CV.SuperLearner}}
feature selection. Will contain elements \code{whichVariable} (a \code{data.frame}),
\code{summary} (a \code{data.frame}), and cvslFull (a \code{list} containing one result of class
\code{CV.SuperLearner} for each \code{method} supplied).
}
\description{
Feature selection via \code{CV.SuperLearner}
}
\examples{
\dontrun{
# remotes::install_github('osofr/simcausal', build_vignettes = FALSE)
dat <- sim_toy_data(n_obs = 200, rnd_seed = 620)
library(SuperLearner)  # for SL.mean, etc.
library(FSelector) # for cutoff.biggest.diff, etc.
res <- cvSLFeatureSelector(dat$Y, dat[,-which(colnames(dat) \%in\% c("ID", "Y"))],
                           family = binomial(), method = "method.NNloglik",
                           SL.library = setNames(list(c("SL.mean", "screen.randomForest.imp"),
                                                      c("SL.mean", "screen.earth.backwardprune")),
                                                 c("random forest biggest diff mean",
                                                   "splines biggest diff mean")),
                           selector.library = data.frame(selector = c("cutoff.biggest.diff",
                                                                      "cutoff.k"),
                                                         k = c(NA, 2),
                                                         rowname = c("biggest diff", "top2"),
                                                         stringsAsFactors = FALSE) \%>\%
                                              tibble::column_to_rownames(),
                           nFolds = 3,
                           verbose = TRUE)

# based on example in SuperLearner package
dat <- sim_sl_data(n_obs = 100, rnd_seed = 1)
res <- cvSLFeatureSelector(dat$Y, dat[,-which(colnames(dat) \%in\% c("ID", "Y"))],
                           family = gaussian(), method = "method.NNLS",
                           SL.library = setNames(list(c("SL.mean", "screen.randomForest.imp"),
                                                      c("SL.mean", "screen.earth.backwardprune")),
                                                 c("random forest biggest diff mean",
                                                   "splines biggest diff mean")),
                           selector.library = data.frame(selector = c("cutoff.biggest.diff",
                                                                     "cutoff.k"),
                                                         k = c(NA, 3),
                                                         rowname = c("biggest diff", "top3"),
                                                         stringsAsFactors = FALSE) \%>\%
                                              tibble::column_to_rownames(),
                           nFolds = 3,
                           verbose = TRUE)
}
}
